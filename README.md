# WebRTC FastAPI Video Chat

A real-time peer-to-peer video chat application built with FastAPI and WebRTC.

## Features

- 🎥 Real-time video and audio communication
- 🔒 Room-based private conversations
- 🌐 WebSocket signaling server
- 📱 Responsive design
- 🎛️ Media controls (mute/unmute, video on/off)
- ⏺️ Recording with client-side speech-to-text
- 🔄 Live recording indicator and shared transcript across the room
- 🔒 Single active recorder per room (others see status and transcript)
- 🧠 LLM summaries (OpenAI or Hugging Face)
- ⬇️ Export summary to PDF
- 👥 Multiple participants support
- 🐳 Docker support

## Quick Start with Docker

### Prerequisites

- Docker and Docker Compose installed
- A webcam and microphone
- Modern web browser

### Run the Application

```bash
# Build and start
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

Access: http://localhost:8000 (or see [Access from Other Devices](#access-from-other-devices))

## Manual Setup (without Docker)

### 1. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run the Application

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## Usage

1. Open http://localhost:8000 in your browser
2. Allow camera and microphone permissions
3. Enter a room name
4. Click "Join Room"
5. Share the room name with others
6. Start video chatting!

### Record + Transcribe Speech

- Click "⏺️ Start Recording" to begin transcribing spoken audio (Chrome-based browsers).
- Click again to stop; the transcript saves to the database.
- Everyone in the same room sees:
  - A live "Recording" indicator with who is recording
  - The evolving transcript in real time
  - Final transcript text appended when speech segments finish

### Summarize + Export

- Click "🧠 Summarize" to generate a concise summary of the room conversation using your configured LLM provider.
- Click "⬇️ Download PDF" to download a well‑structured PDF (title, room, timestamp, content).
- API endpoints:
  - POST `/summaries/room/{room}` → `{ room, summary }`
  - POST `/summaries/room/{room}/pdf` → `application/pdf`

## Access from Other Devices

WebRTC permissions require a **secure context** (HTTPS or localhost). When you visit `http://<your-ip>:8000` from another machine, browsers block camera/mic access. Use one of the following approaches.


### Option A: Secure Tunnel with ngrok

If you prefer not to manage certificates, you can proxy the app through an HTTPS tunnel:

```bash
# Terminal 1
run application

# Terminal 2 (requires an ngrok account and auth token)
ngrok http 8000
```

Use the `https://` forwarding URL generated by ngrok from any device. Camera/mic prompts work because ngrok terminates TLS for you.

## Testing Locally

Open two browser tabs:
- Tab 1: Enter room "test-room" and join
- Tab 2: Enter same room "test-room" and join
- Both tabs should connect and show video

## Docker Commands

```bash
# Build
docker-compose build

# Start
docker-compose up -d

# Stop
docker-compose down

# View logs
docker-compose logs -f

# Restart
docker-compose restart

# Remove everything
docker-compose down -v
```

## Project Structure

```
webrtc-fastapi/
├── app/
│   ├── main.py              # FastAPI app
│   ├── config.py            # Centralized settings from .env
│   ├── db.py                # SQLAlchemy engine/session
│   ├── db_models.py         # ORM models (e.g., Transcript)
│   ├── schemas.py           # Pydantic schemas
│   ├── routers/
│   │   ├── webrtc.py        # WebSocket signaling
│   │   ├── transcripts.py   # REST: store/list transcripts
│   │   └── summaries.py     # REST: summarize + PDF
│   ├── services/
│   │   └── llm/
│   │       ├── base.py      # LLMProvider interface
│   │       ├── factory.py   # Provider selector (OpenAI/HF)
│   │       ├── openai_provider.py
│   │       └── hf_provider.py
│   └── static/
│       ├── css/
│       │   └── style.css
│       ├── js/
│       │   └── webrtc.js
│       └── index.html
├── Dockerfile
├── docker-compose.yml
├── requirements.txt
└── README.md
```

## Configuration

Edit `.env` file:

```
STUN_SERVER=stun:stun.l.google.com:19302
HOST=0.0.0.0
PORT=8000
DATABASE_URL=postgresql+psycopg2://webrtc:webrtc@localhost:5432/webrtc

Using local Postgres (no DB container):
- Ensure your local PostgreSQL is running and accessible on port 5432
- Update credentials in `.env` and `docker-compose.yml` as needed
- For Docker on macOS/Windows, use `host.docker.internal` as the host in `DATABASE_URL`
  Example: `postgresql+psycopg2://webrtc:webrtc@host.docker.internal:5432/webrtc`
- On Linux, use the host IP or set up Docker host networking.

Docker Compose mounts your local `.env` into the container (see `docker-compose.yml`) so the app reads environment variables directly from it.

LLM config (choose one provider):
- OpenAI
  - `LLM_PROVIDER=openai`
  - `OPENAI_API_KEY=sk-...`
  - Optional: `OPENAI_MODEL=gpt-4o-mini`
- Hugging Face
  - `LLM_PROVIDER=huggingface`
  - `HF_API_KEY=hf_...`
  - Optional: `HF_MODEL=facebook/bart-large-cnn`

APIs:
- POST `/transcripts` { room, client_id, language?, text } → stores a transcript row
- POST `/summaries/room/{room}` → returns `{ summary }` using configured LLM
- POST `/summaries/room/{room}/pdf` → returns `application/pdf`
- GET  `/transcripts?room=<name>&limit=<N>` → recent transcript rows
```

## Troubleshooting

### Camera not working
- Check browser permissions
- Use HTTPS (`mkcert` or `ngrok` when testing off-device)
- Try different browser

### Port already in use
```bash
# Use different port
docker-compose up -d -e PORT=8001
```

### Connection failed
- Ensure both users in same room
- Check firewall settings
- View logs: `docker-compose logs -f`

### LLM summary errors
- Error: "LLM provider not configured" → set `LLM_PROVIDER` and the corresponding API key in `.env`.
- Running in Docker: ensure `.env` is mounted (it is by default) and restart after editing.
- OpenAI httpx error → we pin `httpx` to `0.27.x` in `requirements.txt` for compatibility.

### Transcripts not saving
- Only the active recorder saves rows; ensure your device is the recorder.
- DATABASE_URL must point to a reachable Postgres host from inside the container.
- Tables auto‑create on startup; ensure the app started successfully.

## Production Deployment

For production use:
1. Use HTTPS (WebRTC requires secure context)
2. Add TURN servers for NAT traversal
3. Implement authentication
4. Set up monitoring

## License

MIT License

## Support

For issues, please check the logs and browser console (F12).


build:
	docker-compose build

up:
	docker-compose up -d
	@echo "✅ Application started at http://localhost:8000"

dev:
	docker-compose up

down:
	docker-compose down

restart:
	docker-compose restart

logs:
	docker-compose logs -f

clean:
	docker-compose down -v
	docker system prune -f

shell:
	docker-compose exec webrtc-app /bin/bash
